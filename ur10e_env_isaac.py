"""
UR10e PPOç¯å¢ƒ - Isaac Gymç‰ˆæœ¬

åŸºäºIsaac Gymå®ç°çš„UR10eæœºæ¢°è‡‚RL-PIDæ··åˆæ§åˆ¶ç¯å¢ƒ
å°†åŸæœ¬çš„MuJoCoå®ç°è¿ç§»åˆ°Isaac Gymä»¥è·å¾—æ›´å¥½çš„å¹¶è¡Œæ€§èƒ½
"""

# IMPORTANT: Isaac Gym must be imported before PyTorch
from isaacgym import gymapi
from isaacgym import gymtorch
from isaacgym import gymutil
from isaacgym.torch_utils import *

import torch
import numpy as np
import math
import sys
from typing import Dict, Any, List, Tuple, Optional
import os

# å¯¼å…¥è¿åŠ¨å­¦ï¼ˆå»¶è¿Ÿå¯¼å…¥ä»¥é¿å…å¯¼å…¥é¡ºåºé—®é¢˜ï¼‰
ur10e_kinematics_fixed = None
reward_normalizer_module = None

# å¯¼å…¥è®¾å¤‡ä¸€è‡´æ€§æ£€æŸ¥å·¥å…·
from utils import assert_same_device, check_tensor_devices, get_tensor_device, ensure_device

def get_kinematics():
    """å»¶è¿Ÿå¯¼å…¥è¿åŠ¨å­¦æ¨¡å—"""
    global ur10e_kinematics_fixed
    if ur10e_kinematics_fixed is None:
        try:
            from ur10e_kinematics_fixed import UR10eKinematicsFixed
            ur10e_kinematics_fixed = UR10eKinematicsFixed
        except ImportError:
            print("âš ï¸ æ— æ³•å¯¼å…¥è¿åŠ¨å­¦æ¨¡å—ï¼Œä½¿ç”¨ç®€åŒ–å®ç°")
            ur10e_kinematics_fixed = None
    return ur10e_kinematics_fixed

def get_reward_normalizer():
    """è·å–å¥–åŠ±å½’ä¸€åŒ–æ¨¡å— - ä½¿ç”¨utils.pyä¸­çš„å®Œæ•´ç‰ˆæœ¬"""
    # ä¼˜å…ˆå°è¯•ä»å½“å‰utilså¯¼å…¥ï¼ˆä¿®å¤deviceé—®é¢˜çš„ç‰ˆæœ¬ï¼‰
    try:
        from utils import RewardNormalizer
        print("âœ… ä½¿ç”¨utils.pyä¸­çš„RewardNormalizerï¼ˆæ”¯æŒresetå’Œdeviceå‚æ•°ï¼‰")
        return RewardNormalizer
    except ImportError as e:
        print(f"âš ï¸ æ— æ³•å¯¼å…¥utils.pyä¸­çš„RewardNormalizer: {e}")
        print("âš ï¸ å°è¯•ä»çˆ¶ç›®å½•å¯¼å…¥...")
        # å¤‡é€‰æ–¹æ¡ˆï¼šå°è¯•çˆ¶ç›®å½•
        sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'ppo_ur10e'))
        try:
            from utils import RewardNormalizer
            print("âœ… ä½¿ç”¨çˆ¶ç›®å½•çš„RewardNormalizer")
            return RewardNormalizer
        except ImportError:
            print("âŒ æ— æ³•å¯¼å…¥ä»»ä½•RewardNormalizerï¼Œè®­ç»ƒå¯èƒ½å¤±è´¥")
            return None


class UR10ePPOEnvIsaac:
    """
    UR10e PPOç¯å¢ƒ - Isaac Gymç‰ˆæœ¬

    ç‰¹æ€§:
    - æ”¯æŒå¤§è§„æ¨¡å¹¶è¡Œä»¿çœŸ
    - GPUåŠ é€Ÿè®¡ç®—
    - RL-PIDæ··åˆæ§åˆ¶æ¶æ„
    - åŸºäºé›…å¯æ¯”çš„ç²¾ç¡®æ§åˆ¶
    - å¥–åŠ±å½’ä¸€åŒ–
    """

    def __init__(self,
                 config_path: str = "config.yaml",
                 num_envs: int = 512,
                 device_id: int = 0):
        """
        åˆå§‹åŒ–Isaac Gymç¯å¢ƒ

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            num_envs: å¹¶è¡Œç¯å¢ƒæ•°é‡
            device_id: GPUè®¾å¤‡ID
        """
        # åŠ è½½é…ç½®
        self.config = self._load_config(config_path)
        self.num_envs = num_envs
        self.device_id = device_id

        # ğŸ¯ GPUè®¾å¤‡é…ç½®ï¼ˆå‚è€ƒ isaac_gym_manipulator æ¨¡å¼ï¼‰
        if torch.cuda.is_available() and device_id >= 0:
            # æ£€æŸ¥GPUè®¾å¤‡æ˜¯å¦å¯ç”¨
            if device_id < torch.cuda.device_count():
                self.device = torch.device(f'cuda:{device_id}')
                # è®¾ç½®å½“å‰CUDAè®¾å¤‡ï¼ˆç¡®ä¿æ‰€æœ‰æ“ä½œéƒ½åœ¨æŒ‡å®šçš„GPUä¸Šï¼‰
                torch.cuda.set_device(device_id)
            else:
                print(f"[Warning] GPU {device_id} not available, only {torch.cuda.device_count()} GPUs found. Using GPU 0.")
                self.device = torch.device('cuda:0')
                torch.cuda.set_device(0)
                device_id = 0  # æ›´æ–°ä¸ºå®é™…ä½¿ç”¨çš„è®¾å¤‡ID
        else:
            self.device = torch.device('cpu')
            device_id = -1  # CPUæ¨¡å¼

        # UR10eæœºå™¨äººå‚æ•°
        self.num_dofs = 6  # UR10eæœ‰6ä¸ªè‡ªç”±åº¦

        # ï¿½ï¿½å¢ƒå‚æ•°
        self.max_steps = self.config['env']['max_steps']
        self.dt = self.config['env']['dt']

        # UR10eå®˜æ–¹å…³èŠ‚é™åˆ¶ï¼ˆåŸºäºisaac_gym_manipulatorä¸­çš„å®˜æ–¹URDFé…ç½®ï¼‰
        self.joint_limits = np.array([
            [-6.28319, 6.28319],   # shoulder_pan_joint: Â±360Â° = Â±2Ï€ rad
            [-6.28319, 6.28319],   # shoulder_lift_joint: Â±360Â° = Â±2Ï€ rad
            [-3.14159, 3.14159],   # elbow_joint: Â±180Â° = Â±Ï€ rad (äººä¸ºé™åˆ¶é¿å…è§„åˆ’é—®é¢˜)
            [-6.28319, 6.28319],   # wrist_1_joint: Â±360Â° = Â±2Ï€ rad
            [-6.28319, 6.28319],   # wrist_2_joint: Â±360Â° = Â±2Ï€ rad
            [-6.28319, 6.28319]    # wrist_3_joint: Â±360Â° = Â±2Ï€ rad
        ])

        print("ğŸ“ UR10eå®˜æ–¹å…³èŠ‚é™åˆ¶:")
        joint_names = ['shoulder_pan', 'shoulder_lift', 'elbow_joint', 'wrist_1', 'wrist_2', 'wrist_3']
        for i, (name, limits) in enumerate(zip(joint_names, self.joint_limits)):
            limits_deg = np.degrees(limits)
            print(f"  {i+1}. {name:12}: [{limits[0]:.2f}, {limits[1]:.2f}] rad ({limits_deg[0]:.0f}Â°, {limits_deg[1]:.0f}Â°)")

        # åŠ¨ä½œç©ºé—´é™åˆ¶ (PIDå‚æ•°è°ƒåº¦)
        self.action_space_high = np.array([0.5, 0.5, 1.0])  # [kp_scale, kd_scale, ki_enable]
        self.action_space_low = np.array([-0.5, -0.5, 0.0])

        # çŠ¶æ€ç©ºé—´ (16ç»´RL-PIDæ··åˆæ§åˆ¶)
        self.state_dim = 16
        self.action_dim = 3

        # åˆå§‹åŒ–Isaac Gym
        self.gym = gymapi.acquire_gym()
        self._init_simulator()

        # åˆ›å»ºç¯å¢ƒ
        self._create_environments()

        # è¿åŠ¨å­¦è§£ç®—å™¨
        kinematics_class = get_kinematics()
        if kinematics_class is not None:
            self.kinematics = kinematics_class()
        else:
            print("âš ï¸ ä½¿ç”¨ç®€åŒ–è¿åŠ¨å­¦å®ç°")
            self.kinematics = None

        # ğŸ¯ å¥–åŠ±å½’ä¸€åŒ–å™¨ (æ¯ä¸ªç¯å¢ƒç‹¬ç«‹)
        reward_config = self.config.get('reward_normalization', {})

        if reward_config.get('enabled', True):
            reward_normalizer_class = get_reward_normalizer()
            if reward_normalizer_class is not None:
                self.reward_normalizers = [
                    reward_normalizer_class(
                        gamma=reward_config.get('gamma', 0.99),
                        clip_range=reward_config.get('clip_range', 5.0),
                        normalize_method=reward_config.get('normalize_method', 'running_stats'),
                        warmup_steps=reward_config.get('warmup_steps', 100)
                    ) for _ in range(num_envs)
                ]
                print(f"âœ… å¯ç”¨å¥–åŠ±å½’ä¸€åŒ–: gamma={reward_config.get('gamma', 0.99)}, clip_range={reward_config.get('clip_range', 5.0)}")
            else:
                print("âš ï¸ æ— æ³•åŠ è½½å¥–åŠ±å½’ä¸€åŒ–å™¨ï¼Œä½¿ç”¨åŸå§‹å¥–åŠ±")
                self.reward_normalizers = [None] * num_envs
        else:
            print("ğŸ“ å¥–åŠ±å½’ä¸€åŒ–å·²ç¦ç”¨")
            self.reward_normalizers = [None] * num_envs

        # çŠ¶æ€å˜é‡
        self.current_step = 0
        self.episode_steps = torch.zeros(num_envs, device=self.device)  # æ¯ä¸ªç¯å¢ƒçš„å½“å‰episodeæ­¥æ•°
        self.debug_step = 0  # è°ƒè¯•æ­¥æ•°è®¡æ•°å™¨
        self.start_joint_angles = None
        self.target_positions = None
        self.prev_position_errors = None

        print(f"âœ… Isaac Gym UR10eç¯å¢ƒåˆå§‹åŒ–å®Œæˆ")
        print(f"   å¹¶è¡Œç¯å¢ƒæ•°: {num_envs}")
        print(f"   è®¾å¤‡ID: {device_id}")
        print(f"   çŠ¶æ€ç©ºé—´: {self.state_dim}ç»´ (RL-PIDæ··åˆï¿½ï¿½åˆ¶)")
        print(f"   åŠ¨ä½œç©ºé—´: {self.action_dim}ç»´ (PIDå‚æ•°è°ƒåº¦)")

        # ğŸ¯ æ˜¾ç¤ºå®˜æ–¹UR10e PIDå‚æ•°
        if 'pid_params' in self.config and 'base_gains' in self.config['pid_params']:
            pid_params = self.config['pid_params']['base_gains']
            print(f"ğŸ¯ ä½¿ç”¨å®˜æ–¹UR10e PIDå‚æ•°:")
            print(f"   Kp: {pid_params['p']}")
            print(f"   Kd: {pid_params['d']}")
            print(f"   Ki: {pid_params['i']}")

    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        import yaml
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
        except FileNotFoundError:
            print(f"âš ï¸ é…ç½®æ–‡ä»¶ {config_path} æœªæ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            config = self._get_default_config()
        return config

    def _get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            'env': {
                'max_steps': 1000,
                'dt': 0.01,
                'action_bound': 0.03,
                'xml_path': '../universal_robots_ur10e/ur10e_mujoco/scene.xml'
            },
            'reward': {
                'accuracy': {'weight': 5.0, 'threshold': 0.005},
                'stability': {'weight': 0.5},
                'speed': {'weight': 1.0},
                'energy': {'weight': 0.001},
                'extra': {'success_reward': 10.0}
            }
        }

    def _init_simulator(self):
        """åˆå§‹åŒ–Isaac Gymä»¿çœŸå™¨"""
        # åˆ›å»ºä»¿çœŸå™¨ - åŸºäºæˆåŠŸçš„isaac_gym_manipulatoré…ç½®
        sim_params = gymapi.SimParams()
        sim_params.dt = self.dt
        sim_params.substeps = 2  # ä½¿ç”¨æˆåŠŸé…ç½®çš„å­æ­¥æ•°
        sim_params.up_axis = gymapi.UP_AXIS_Z

        # è®¾ç½®é‡åŠ›ï¼ˆå‚è€ƒæˆåŠŸé…ç½®ï¼‰
        sim_params.gravity.x = 0
        sim_params.gravity.y = 0
        sim_params.gravity.z = -9.81

        # è®¾ç½®ç‰©ç†å¼•æ“å‚æ•° - ä½¿ç”¨æˆåŠŸé…ç½®
        sim_params.physx.solver_type = 1  # ä½¿ç”¨solver_type=1ï¼ˆæˆåŠŸé…ç½®ï¼‰
        sim_params.physx.num_position_iterations = 4  # ä½ç½®è¿­ä»£æ¬¡æ•°
        # è·å–ä»¿çœŸé…ç½®
        simulator_config = self.config.get('simulator', {})

        sim_params.physx.num_velocity_iterations = 1  # é€Ÿåº¦è¿­ä»£æ¬¡æ•°
        sim_params.physx.num_threads = 0  # çº¿ç¨‹æ•°ï¼ˆ0=è‡ªåŠ¨ï¼‰
        sim_params.physx.use_gpu = simulator_config.get('use_gpu', True)
        # ä¿®å¤ï¼šæ­£ç¡®è®¾ç½®GPUæ¸²æŸ“ç®¡çº¿ï¼Œé¿å…CUDAå†…å­˜é—®é¢˜
        sim_params.use_gpu_pipeline = simulator_config.get('use_gpu_pipeline', False)
        enable_rendering = simulator_config.get('enable_rendering', False)
        graphics_device = simulator_config.get('graphics_device', self.device_id)

        # æ ¹æ®æ¸²æŸ“è®¾ç½®é€‰æ‹©å›¾å½¢è®¾å¤‡
        if enable_rendering:
            graphics_device_id = graphics_device
            print(f"ğŸ¬ å¯ç”¨æ¸²æŸ“æ¨¡å¼ï¼Œå›¾å½¢è®¾å¤‡: {graphics_device_id}")
        else:
            graphics_device_id = -1  # æ— å¤´æ¨¡å¼
            print("ğŸ–¥ï¸ æ— å¤´æ¨¡å¼ï¼Œç¦ç”¨æ¸²æŸ“")

        # åˆ›å»ºä»¿çœŸå™¨ï¼ˆä½¿ç”¨PhysXè€ŒéFleXï¼Œå‚è€ƒisaac_gym_manipulatorï¼‰
        self.sim = self.gym.create_sim(
            compute_device=self.device_id,
            graphics_device=graphics_device_id,
            type=gymapi.SIM_PHYSX,  # å…³é”®ï¼šä½¿ç”¨PhysXè€Œä¸æ˜¯é»˜è®¤çš„FleX
            params=sim_params
        )

        if self.sim is None:
            raise Exception("Failed to create Isaac Gym simulator")

    def _create_environments(self):
        """åˆ›å»ºå¹¶è¡Œç¯å¢ƒ - å‚è€ƒisaac_gym_manipulatorå®ç°"""

        # æ·»åŠ åœ°é¢ - å‚è€ƒisaac_gym_manipulator
        plane_params = gymapi.PlaneParams()
        plane_params.normal = gymapi.Vec3(0.0, 0.0, 1.0)
        plane_params.distance = 0
        self.gym.add_ground(self.sim, plane_params)
        print("âœ… å·²æ·»åŠ åœ°é¢")

        # æ¸²æŸ“é…ç½®
        self.enable_rendering = self.config.get('simulator', {}).get('enable_rendering', False)
        self.graphics_device = self.config.get('simulator', {}).get('graphics_device', self.device_id)

        if self.enable_rendering:
            print(f"ğŸ¬ å¯ç”¨Isaac Gymæ¸²æŸ“ï¼Œå›¾å½¢è®¾å¤‡: {self.graphics_device}")
        else:
            print("ğŸ–¥ï¸  æ— å¤´æ¨¡å¼è¿è¡Œï¼Œç¦ç”¨æ¸²æŸ“")

        # è·å–UR10eèµ„äº§è·¯å¾„
        asset_root = "."  # å½“å‰ç›®å½•ï¼ŒåŒ…å«ur10e_isaac.urdf
        asset_file = "scene.xml"

        # åŠ è½½UR10eèµ„äº§ - å‚è€ƒisaac_gym_manipulatorè®¾ç½®
        ur10e_asset_options = gymapi.AssetOptions()
        ur10e_asset_options.flip_visual_attachments = True  # å¯ç”¨ä»¥æ­£ç¡®æ˜¾ç¤ºmesh
        ur10e_asset_options.fix_base_link = True
        ur10e_asset_options.use_mesh_materials = True  # å¯ç”¨æè´¨
        ur10e_asset_options.override_com = True
        ur10e_asset_options.override_inertia = True
        ur10e_asset_options.vhacd_enabled = True  # å¯ç”¨VHACDå¤„ç†å‡¸åŒ…ç¢°æ’
        ur10e_asset_options.vhacd_params = gymapi.VhacdParams()
        ur10e_asset_options.vhacd_params.resolution = 300000
        ur10e_asset_options.default_dof_drive_mode = gymapi.DOF_MODE_EFFORT  # ä¿®å¤ï¼šé»˜è®¤åŠ›çŸ©æ§åˆ¶æ¨¡å¼

        # ä½¿ç”¨æˆ‘ä»¬åˆ›å»ºçš„URDFæ–‡ä»¶
        urdf_path = os.path.join(asset_root, "ur10e_isaac.urdf")
        if not os.path.exists(urdf_path):
            # å¦‚æœURDFä¸å­˜åœ¨ï¼Œå›é€€åˆ°åˆ›å»ºç®€å•URDF
            urdf_path = self._create_ur10e_urdf(asset_root)
        else:
            print(f"âœ… ä½¿ç”¨URDFæ–‡ä»¶: {urdf_path}")

        try:
            # ä½¿ç”¨load_assetè€Œä¸æ˜¯load_urdfï¼Œå‚è€ƒisaac_gym_manipulator
            self.ur10e_asset = self.gym.load_asset(
                self.sim, asset_root, "ur10e_isaac.urdf", ur10e_asset_options
            )
            print(f"âœ… UR10eèµ„äº§åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âŒ UR10eèµ„äº§åŠ è½½å¤±è´¥: {e}")
            print(f"   èµ„äº§è·¯å¾„: {asset_root}/ur10e_isaac.urdf")
            raise

        # è®¾ç½®ç¯å¢ƒé—´è·
        env_spacing = 2.0
        env_lower = gymapi.Vec3(-env_spacing, -env_spacing, 0.0)
        env_upper = gymapi.Vec3(env_spacing, env_spacing, env_spacing)

        # åˆ›å»ºç¯å¢ƒ
        self.envs = []
        self.ur10e_handles = []

        for i in range(self.num_envs):
            # åˆ›å»ºç¯å¢ƒ
            env = self.gym.create_env(
                self.sim, env_lower, env_upper, int(np.sqrt(self.num_envs))
            )
            self.envs.append(env)

            # åˆ›å»ºUR10eæœºå™¨äºº
            ur10e_handle = self.gym.create_actor(
                env, self.ur10e_asset, gymapi.Transform(), f"ur10e_{i}"
            )
            self.ur10e_handles.append(ur10e_handle)

            # è®¾ç½®UR10eå±æ€§
            self.gym.set_actor_dof_properties(env, ur10e_handle, self._get_ur10e_dof_props())

        # åˆ›å»ºå¼ é‡è§†å›¾
        self._create_tensor_views()

        # è®¾ç½®æ¸²æŸ“å™¨ï¼ˆå¦‚æœå¯ç”¨æ¸²æŸ“ï¼‰
        if self.enable_rendering:
            self._setup_renderer()

    def _create_ur10e_urdf(self, asset_root: str) -> str:
        """åˆ›å»ºUR10e URDFæ–‡ä»¶ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰"""
        # è¿™é‡Œåº”è¯¥æœ‰ä¸€ä¸ªURDFåˆ°MuJoCo XMLçš„è½¬æ¢
        # æš‚æ—¶è¿”å›ä¸€ä¸ªå ä½ç¬¦è·¯å¾„
        urdf_path = os.path.join(asset_root, "ur10e.urdf")
        if not os.path.exists(urdf_path):
            # åˆ›å»ºä¸€ä¸ªç®€å•çš„URDFæ–‡ä»¶
            urdf_content = self._generate_simple_urdf()
            with open(urdf_path, 'w') as f:
                f.write(urdf_content)
        return urdf_path

    def _generate_simple_urdf(self) -> str:
        """ç”Ÿæˆç®€å•çš„UR10e URDF"""
        return """<?xml version="1.0"?>
<robot name="ur10e">
  <link name="base_link">
    <inertial>
      <mass value="10"/>
      <inertia ixx="1" ixy="0" ixz="0" iyy="1" iyz="0" izz="1"/>
    </inertial>
  </link>

  <!-- UR10e 6ä¸ªå…³èŠ‚ -->
  <link name="shoulder_pan_joint">
    <inertial>
      <mass value="5"/>
      <inertia ixx="0.1" ixy="0" ixz="0" iyy="0.1" iyz="0" izz="0.1"/>
    </inertial>
  </link>

  <link name="shoulder_lift_joint">
    <inertial>
      <mass value="5"/>
      <inertia ixx="0.1" ixy="0" ixz="0" iyy="0.1" iyz="0" izz="0.1"/>
    </inertial>
  </link>

  <link name="elbow_joint">
    <inertial>
      <mass value="5"/>
      <inertia ixx="0.1" ixy="0" ixz="0" iyy="0.1" iyz="0" izz="0.1"/>
    </inertial>
  </link>

  <link name="wrist_1_joint">
    <inertial>
      <mass value="3"/>
      <inertia ixx="0.05" ixy="0" ixz="0" iyy="0.05" iyz="0" izz="0.05"/>
    </inertial>
  </link>

  <link name="wrist_2_joint">
    <inertial>
      <mass value="3"/>
      <inertia ixx="0.05" ixy="0" ixz="0" iyy="0.05" iyz="0" izz="0.05"/>
    </inertial>
  </link>

  <link name="wrist_3_joint">
    <inertial>
      <mass value="2"/>
      <inertia ixx="0.02" ixy="0" ixz="0" iyy="0.02" iyz="0" izz="0.02"/>
    </inertial>
  </link>

  <!-- å…³èŠ‚è¿æ¥ -->
  <joint name="shoulder_pan_joint" type="revolute" parent="base_link" child="shoulder_pan_joint">
    <axis xyz="0 0 1"/>
    <limit lower="-3.14159" upper="3.14159" effort="100"/>
  </joint>

  <joint name="shoulder_lift_joint" type="revolute" parent="shoulder_pan_joint" child="shoulder_lift_joint">
    <axis xyz="0 1 0"/>
    <limit lower="-3.14159" upper="3.14159" effort="100"/>
  </joint>

  <joint name="elbow_joint" type="revolute" parent="shoulder_lift_joint" child="elbow_joint">
    <axis xyz="0 1 0"/>
    <limit lower="-3.14159" upper="3.14159" effort="100"/>
  </joint>

  <joint name="wrist_1_joint" type="revolute" parent="elbow_joint" child="wrist_1_joint">
    <axis xyz="0 1 0"/>
    <limit lower="-3.14159" upper="3.14159" effort="50"/>
  </joint>

  <joint name="wrist_2_joint" type="revolute" parent="wrist_1_joint" child="wrist_2_joint">
    <axis xyz="0 0 1"/>
    <limit lower="-3.14159" upper="3.14159" effort="50"/>
  </joint>

  <joint name="wrist_3_joint" type="revolute" parent="wrist_2_joint" child="wrist_3_joint">
    <axis xyz="0 0 1"/>
    <limit lower="-3.14159" upper="3.14159" effort="50"/>
  </joint>
</robot>"""

    def _get_ur10e_dof_props(self):
        """è·å–UR10e DOFå±æ€§"""
        dof_props = self.gym.get_actor_dof_properties(self.envs[0], self.ur10e_handles[0])

        # è®¾ç½®å…³èŠ‚å±æ€§ï¼ˆä¿®å¤ï¼šä½¿ç”¨EFFORTæ¨¡å¼æ”¯æŒåŠ›çŸ©æ§åˆ¶ï¼‰
        dof_props["driveMode"] = gymapi.DOF_MODE_EFFORT  # å…³é”®ä¿®å¤ï¼šåŠ›çŸ©æ§åˆ¶æ¨¡å¼
        dof_props["stiffness"] = 0.0
        dof_props["damping"] = 0.0

        # è®¾ç½®å…³èŠ‚é™åˆ¶
        for i in range(6):
            dof_props["lower"][i] = self.joint_limits[i][0]
            dof_props["upper"][i] = self.joint_limits[i][1]

        return dof_props

    def _create_tensor_views(self):
        """åˆ›å»ºGPUå¼ é‡è§†å›¾"""
        # è§‚æµ‹ç©ºé—´
        self.obs_buf = torch.zeros(
            (self.num_envs, self.state_dim),
            device=self.device, dtype=torch.float32
        )

        # åŠ¨ä½œç©ºé—´
        self.actions_buf = torch.zeros(
            (self.num_envs, self.action_dim),
            device=self.device, dtype=torch.float32
        )

        # å¥–åŠ±
        self.rewards_buf = torch.zeros(
            (self.num_envs,),
            device=self.device, dtype=torch.float32
        )

        # å®Œæˆæ ‡å¿—
        self.dones_buf = torch.zeros(
            (self.num_envs,),
            device=self.device, dtype=torch.bool
        )

        # è·å–çŠ¶æ€å’ŒåŠ¨ä½œçš„å¼ é‡è§†å›¾
        self.root_states = self.gym.acquire_actor_root_state_tensor(self.sim)
        self.dof_states = self.gym.acquire_dof_state_tensor(self.sim)

        self.root_states = gymtorch.wrap_tensor(self.root_states)
        self.dof_states = gymtorch.wrap_tensor(self.dof_states)

    def _setup_renderer(self):
        """è®¾ç½®Isaac Gymæ¸²æŸ“å™¨ - å‚è€ƒisaac_gym_manipulatorå®ç°"""
        try:
            # åˆ›å»ºviewer - ä½¿ç”¨æ ‡å‡†Isaac Gym viewer
            self.viewer = self.gym.create_viewer(
                self.sim,
                gymapi.CameraProperties()
            )

            if self.viewer is None:
                print("âš ï¸ æ— æ³•åˆ›å»ºviewerï¼Œä½¿ç”¨æ— å¤´æ¨¡å¼")
                self.enable_rendering = False
                return

            # è®¾ç½®ç›¸æœºè§†è§’ - å‚è€ƒisaac_gym_manipulatorå®ç°
            cam_pos = gymapi.Vec3(2.0, 0.0, 2.0)
            cam_target = gymapi.Vec3(0.0, 0.0, 0.0)
            # ä½¿ç”¨Noneä½œä¸ºç¯å¢ƒå‚æ•°ï¼Œå‚è€ƒisaac_gym_manipulator
            self.gym.viewer_camera_look_at(self.viewer, None, cam_pos, cam_target)

            print(f"âœ… æ¸²æŸ“å™¨è®¾ç½®å®Œæˆï¼Œä½¿ç”¨æ ‡å‡†Isaac Gym viewer")
            print("   å‚è€ƒisaac_gym_manipulatoræˆåŠŸå®ç°")

            # æµ‹è¯•æ¸²æŸ“ï¼ˆä½¿ç”¨ç®€å•æ–¹å¼ï¼‰
            self._test_render_simple()

        except Exception as e:
            print(f"âš ï¸ æ¸²æŸ“å™¨è®¾ç½®å¤±è´¥: {e}")
            print("   ç»§ç»­ä½¿ç”¨æ— å¤´æ¨¡å¼")
            self.enable_rendering = False
            self.viewer = None

    def _test_render_simple(self):
        """æµ‹è¯•æ¸²æŸ“åŠŸèƒ½ï¼ˆå‚è€ƒisaac_gym_manipulatorå®ç°ï¼‰"""
        try:
            # è¿è¡Œå‡ æ­¥ä»¿çœŸè¿›è¡Œæµ‹è¯•
            for i in range(3):
                self.gym.simulate(self.sim)
                self.gym.fetch_results(self.sim, True)

                # ä½¿ç”¨æ ‡å‡†å›¾å½¢æ›´æ–°
                self.gym.step_graphics(self.sim)

                # ç»˜åˆ¶viewer
                if self.viewer is not None:
                    self.gym.draw_viewer(self.viewer, self.sim, True)

                # çŸ­æš‚å»¶è¿Ÿè®©çª—å£æ˜¾ç¤º
                if i == 0:
                    import time
                    time.sleep(0.1)

            print("âœ… æ¸²æŸ“æµ‹è¯•é€šè¿‡")
        except Exception as e:
            print(f"âš ï¸ æ¸²æŸ“æµ‹è¯•å¤±è´¥: {e}")
            print("   å¯èƒ½æ˜¯ç¯å¢ƒæˆ–é©±åŠ¨é—®é¢˜ï¼Œä½†è®­ç»ƒä»å¯ç»§ç»­")
            # ä¸ç¦ç”¨æ¸²æŸ“ï¼Œå¯èƒ½åœ¨å®é™…è¿è¡Œæ—¶å¯ä»¥å·¥ä½œ

    def get_num_envs(self) -> int:
        """è·å–ç¯å¢ƒæ•°é‡"""
        return self.num_envs

    def reset(self) -> torch.Tensor:
        """
        é‡ç½®æ‰€æœ‰ç¯å¢ƒ

        Returns:
            obs: åˆå§‹è§‚æµ‹å¼ é‡ [num_envs, state_dim]
        """
        # éšæœºç”Ÿæˆèµ·å§‹å…³èŠ‚è§’åº¦
        self.start_joint_angles = self._sample_random_joint_angles_batch()

        # éšæœºç”Ÿæˆç›®æ ‡ä½ç½®
        self.target_positions = self._sample_random_target_positions_batch()

        # è®¾ç½®åˆå§‹çŠ¶æ€ï¼ˆå‚è€ƒ isaac_gym_manipulator æ¨¡å¼ï¼Œé¿å…CUDAå†…å­˜é”™è¯¯ï¼‰
        # ç›´æ¥ä½¿ç”¨ start_idx:end_idx æ‰¹é‡è®¾ç½®ï¼Œè€Œä¸æ˜¯é€ä¸ªç´¢å¼•
        for i in range(self.num_envs):
            # ç¡®ä¿å…³èŠ‚è§’åº¦æ˜¯6ç»´çš„
            joint_angles = self.start_joint_angles[i]
            if len(joint_angles) != 6:
                if len(joint_angles) > 6:
                    joint_angles = joint_angles[:6]
                else:
                    joint_angles = torch.cat([joint_angles, torch.zeros(6-len(joint_angles), device=self.device)])

            # ä½¿ç”¨æ‰¹é‡åˆ‡ç‰‡æ“ä½œï¼ˆisaac_gym_manipulator æˆåŠŸæ¨¡å¼ï¼‰
            start_idx = i * self.num_dofs
            end_idx = (i + 1) * self.num_dofs
            self.dof_states[start_idx:end_idx, 0] = joint_angles.to(self.device)  # ä½ç½® - ç¡®ä¿åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
            self.dof_states[start_idx:end_idx, 1] = 0.0  # é€Ÿåº¦

        # åº”ç”¨åˆ°ä»¿çœŸï¼ˆisaac_gym_manipulator æ¨¡å¼ï¼‰
        self.gym.set_dof_state_tensor(self.sim, gymtorch.unwrap_tensor(self.dof_states))

        # è¿è¡Œå‡ æ­¥simulationè®©æœºæ¢°è‡‚ç¨³å®šï¼ˆå‚è€ƒisaac_gym_manipulatorï¼‰
        for _ in range(10):
            self.gym.simulate(self.sim)
            self.gym.fetch_results(self.sim, True)

        # åˆ·æ–°çŠ¶æ€å¼ é‡ï¼ˆisaac_gym_manipulator æ¨¡å¼ï¼‰
        self.gym.refresh_rigid_body_state_tensor(self.sim)
        self.gym.refresh_dof_state_tensor(self.sim)

        # é‡ç½®å†…éƒ¨çŠ¶æ€
        self.current_step = 0
        self.episode_steps.zero_()  # é‡ç½®æ¯ä¸ªç¯å¢ƒçš„episodeæ­¥æ•°
        self.prev_position_errors = torch.ones(self.num_envs, device=self.device) * 10.0

        # é‡ç½®å¥–åŠ±å½’ä¸€åŒ–å™¨
        for normalizer in self.reward_normalizers:
            normalizer.reset()

        # æ¨è¿›ä¸€æ­¥
        self.gym.simulate(self.sim)
        self.gym.fetch_results(self.sim, True)

        # è·å–åˆå§‹è§‚æµ‹
        obs = self._get_states()

        return obs

    def step(self, actions: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, Dict[str, Any]]:
        """
        æ‰§è¡Œä¸€æ­¥ä»¿çœŸ

        Args:
            actions: PIDè°ƒåº¦åŠ¨ä½œ [num_envs, 3] [kp_scale, kd_scale, ki_enable]

        Returns:
            obs: ä¸‹ä¸€æ­¥çŠ¶æ€ [num_envs, state_dim]
            rewards: å¥–åŠ± [num_envs]
            dones: å®Œæˆæ ‡å¿— [num_envs]
            info: é¢å¤–ä¿¡æ¯
        """
        # å¢åŠ è°ƒè¯•æ­¥æ•°è®¡æ•°å™¨
        self.debug_step += 1

        # è®¾å¤‡ä¸€è‡´æ€§æ£€æŸ¥
        actions = ensure_device(actions, self.device)

        # è°ƒè¯•ä¿¡æ¯ï¼ˆå¯é€‰æ‹©æ€§å¯ç”¨ï¼‰
        if hasattr(self, '_debug_mode') and self._debug_mode:
            actual_device = actions.device
            expected_device = self.device
            if actual_device != expected_device:
                print(f"âš ï¸ Stepè¾“å…¥è®¾å¤‡ä¸åŒ¹é…: actionsåœ¨{actual_device}, æœŸæœ›åœ¨{expected_device}")

        self.actions_buf = actions

        # æ‰§è¡ŒRL-PIDæ§åˆ¶
        self._apply_rl_pid_control(actions)

        # æ¨è¿›ä¸€æ­¥
        self.gym.simulate(self.sim)
        self.gym.fetch_results(self.sim, True)
        self.gym.refresh_dof_state_tensor(self.sim)

        # æ¸²æŸ“ï¼ˆå¦‚æœå¯ç”¨ï¼‰- å‚è€ƒisaac_gym_manipulatoræˆåŠŸå®ç°
        if self.enable_rendering:
            try:
                # ç»˜åˆ¶ç›®æ ‡ç‚¹ä¸ºçº¢è‰²çƒä½“
                self._draw_target_sphere()

                # ä½¿ç”¨Isaac Gymæ ‡å‡†çš„å›¾å½¢æ›´æ–°æ–¹å¼
                self.gym.step_graphics(self.sim)

                # å¦‚æœæœ‰viewerï¼Œç»˜åˆ¶viewer
                if hasattr(self, 'viewer') and self.viewer is not None:
                    self.gym.draw_viewer(self.viewer, self.sim, True)

            except Exception as e:
                # é™é»˜å¤„ç†æ¸²æŸ“é”™è¯¯ï¼Œé¿å…ä¸­æ–­è®­ç»ƒ
                if hasattr(self, '_debug_mode') and self._debug_mode:
                    print(f"âš ï¸ æ¸²æŸ“é”™è¯¯: {e}")
                pass

        # è·å–æ–°çŠ¶æ€
        obs = self._get_states()

        # è®¡ç®—å¥–åŠ±
        rewards = self._compute_rewards_batch(actions)

        # æ£€æŸ¥å®Œæˆæ¡ä»¶
        dones = self._check_done_batch()

        # å¤„ç†å®Œæˆçš„episode - é‡ç½®ç›¸å…³çŠ¶æ€
        for i in range(self.num_envs):
            if dones[i]:
                self.episode_steps[i] = 0  # é‡ç½®è¯¥ç¯å¢ƒçš„episodeæ­¥æ•°

        # æ›´æ–°å¥–åŠ±å½’ä¸€åŒ–å™¨
        for i in range(self.num_envs):
            if not dones[i]:
                if self.reward_normalizers[i] is not None:
                    self.reward_normalizers[i].update(rewards[i].item())
                    rewards[i] = self.reward_normalizers[i].normalize(rewards[i].item())
                # å¦‚æœæ²¡æœ‰å½’ä¸€åŒ–å™¨ï¼Œä½¿ç”¨åŸå§‹å¥–åŠ±

        self.current_step += 1
        self.episode_steps += 1  # æ¯ä¸ªç¯å¢ƒçš„episodeæ­¥æ•°+1

        # æ„å»ºä¿¡æ¯å­—å…¸
        info = {
            'step': self.current_step,
            'episode_steps': self.episode_steps.clone(),  # æ·»åŠ episodeæ­¥æ•°ä¿¡æ¯
            'target_positions': self.target_positions.detach().cpu().numpy()
        }

        return obs, rewards, dones, info

    def _sample_random_joint_angles_batch(self) -> torch.Tensor:
        """æ‰¹é‡é‡‡æ ·éšæœºå…³èŠ‚è§’åº¦"""
        angles = torch.zeros((self.num_envs, 6), device=self.device)

        for i in range(6):
            low, high = self.joint_limits[i]
            angles[:, i] = torch.rand(
                self.num_envs, device=self.device
            ) * (high - low) * 0.5 + low * 0.5  # ä½¿ç”¨è¾ƒå°çš„èŒƒå›´

        return angles

    def _sample_random_target_positions_batch(self) -> torch.Tensor:
        """
        ğŸ¯ æ‰¹é‡é‡‡æ ·éšæœºç›®æ ‡ä½ç½®ï¼ˆåŸºäºconfigé…ç½®ï¼‰

        ä»configä¸­è¯»å–ç›®æ ‡ä½ç½®èŒƒå›´ï¼Œä¾¿äºè°ƒæ•´UR10eå·¥ä½œç©ºé—´
        """
        # ä»configä¸­è¯»å–ç›®æ ‡ä½ç½®èŒƒå›´
        target_range = self.config['env']['target_range']
        x_range = target_range['x']
        y_range = target_range['y']
        z_range = target_range['z']

        target_positions = torch.zeros((self.num_envs, 3), device=self.device)

        # åœ¨æŒ‡å®šèŒƒå›´å†…éšæœºç”Ÿæˆç›®æ ‡ä½ç½®
        target_positions[:, 0] = torch.rand(self.num_envs, device=self.device) * (x_range[1] - x_range[0]) + x_range[0]
        target_positions[:, 1] = torch.rand(self.num_envs, device=self.device) * (y_range[1] - y_range[0]) + y_range[0]
        target_positions[:, 2] = torch.rand(self.num_envs, device=self.device) * (z_range[1] - z_range[0]) + z_range[0]

        # è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°ç¬¬ä¸€ä¸ªç¯å¢ƒçš„ç›®æ ‡ä½ç½®
        if hasattr(self, 'debug_step') and self.debug_step % 500 == 0:  # æ¯500æ­¥æ‰“å°ä¸€æ¬¡
            print(f"ğŸ¯ ç›®æ ‡ä½ç½®æ›´æ–°: [{target_positions[0].cpu().numpy().tolist()}]")

        return target_positions

    def _get_states(self) -> torch.Tensor:
        """è·å–æ‰€æœ‰ç¯å¢ƒçš„å½“å‰çŠ¶æ€"""
        states = torch.zeros((self.num_envs, self.state_dim), device=self.device)

        # è·å–å½“å‰å…³èŠ‚è§’åº¦å’Œé€Ÿåº¦
        current_angles, current_velocities = self._get_joint_angles_and_velocities()

        # è®¡ç®—æœ«ç«¯ä½ç½®ï¼ˆè¿™é‡Œéœ€è¦Isaac Gymçš„å‰å‘åŠ¨åŠ›å­¦ï¼‰
        current_positions = self._compute_end_effector_positions_batch(current_angles)

        # æ„å»ºçŠ¶æ€å‘é‡ (16ç»´RL-PIDæ··åˆæ§åˆ¶)
        # [current_angles(6), current_velocities(6), current_position(3), distance_to_target(1)]
        distance_to_target = torch.norm(current_positions - self.target_positions, dim=1, keepdim=True)

        states[:, 0:6] = current_angles
        states[:, 6:12] = current_velocities
        states[:, 12:15] = current_positions
        states[:, 15] = distance_to_target.squeeze()

        # è®¾å¤‡ä¸€è‡´æ€§æ£€æŸ¥
        if hasattr(self, '_debug_mode') and self._debug_mode:
            if not check_tensor_devices({'states': states, 'target_positions': self.target_positions}, "_get_states"):
                print(f"âš ï¸ _get_statesè®¾å¤‡ä¸ä¸€è‡´: statesåœ¨{states.device}, target_positionsåœ¨{self.target_positions.device}")

        return states

    def _compute_end_effector_positions_batch(self, joint_angles: torch.Tensor) -> torch.Tensor:
        """æ‰¹é‡è®¡ç®—æœ«ç«¯æ‰§ï¿½ï¿½ï¿½å™¨ä½ç½®"""
        # ç¡®ä¿è¾“å…¥å¼ é‡åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        joint_angles = joint_angles.to(self.device)
        # ä½¿ç”¨è¿åŠ¨å­¦è§£ç®—å™¨è®¡ç®—æœ«ç«¯ä½ç½®
        positions = torch.zeros((self.num_envs, 3), device=self.device)

        for i in range(self.num_envs):
            angles_np = joint_angles[i].detach().cpu().numpy()
            if self.kinematics is not None:
                T = self.kinematics.forward_kinematics(angles_np)
                positions[i] = torch.tensor(T[:3, 3], device=self.device)
            else:
                # ç®€åŒ–ä½ç½®è®¡ç®—ï¼ˆè¿‘ä¼¼ï¼‰
                positions[i] = torch.tensor([
                    0.8 * np.cos(angles_np[0]) * np.cos(angles_np[1]),
                    0.8 * np.cos(angles_np[0]) * np.sin(angles_np[1]),
                    0.8 * np.sin(angles_np[1]) + 0.3
                ], device=self.device)

        return positions

    def _apply_rl_pid_control(self, actions: torch.Tensor):
        """åº”ç”¨RL-PIDæ§åˆ¶ï¼ˆä½¿ç”¨Isaac Gymå®˜æ–¹franka_osc.pyçš„æ­£ç¡®æ¨¡å¼ï¼‰"""
        # è§£æåŠ¨ä½œ
        kp_scale = actions[:, 0]
        kd_scale = actions[:, 1]
        ki_enable = actions[:, 2]

        # è·å–å½“å‰çŠ¶æ€
        current_angles, current_velocities = self._get_joint_angles_and_velocities()
        current_positions = self._compute_end_effector_positions_batch(current_angles)

        # è®¡ç®—ä½ç½®è¯¯å·®
        position_errors = self.target_positions - current_positions
        distance_errors = torch.norm(position_errors, dim=1)

        # ğŸ¯ è°ƒè¯•ä¿¡æ¯ï¼šæ¯100æ­¥æ‰“å°ä¸€æ¬¡ä½ç½®å’Œè¯¯å·®ä¿¡æ¯
        if hasattr(self, 'debug_step') and self.debug_step % 100 == 0:
            print(f"\nğŸ“Š === æ­¥éª¤ {self.debug_step} è°ƒè¯•ä¿¡æ¯ ===")
            for i in range(min(self.num_envs, 2)):  # åªæ‰“å°å‰2ä¸ªç¯å¢ƒ
                print(f"ğŸ¤– ç¯å¢ƒ{i}:")
                print(f"   å½“å‰æœ«ç«¯ä½ç½®: [{current_positions[i].cpu().numpy().tolist()}]")
                print(f"   ç›®æ ‡ä½ç½®: [{self.target_positions[i].cpu().numpy().tolist()}]")
                print(f"   ä½ç½®è¯¯å·®: [{position_errors[i].cpu().numpy().tolist()}]")
                print(f"   è·ç¦»è¯¯å·®: {distance_errors[i].item():.4f}m")
                print(f"   å…³èŠ‚è§’åº¦: [{current_angles[i].cpu().numpy().tolist()}]")

        # æ‰¹é‡è®¡ç®—æ‰€æœ‰ç¯å¢ƒçš„æ§åˆ¶åŠ›çŸ©ï¼ˆä¿®å¤è®¾å¤‡é—®é¢˜ï¼šIsaac GymæœŸæœ›CPUå¼ é‡ï¼‰
        # åˆå§‹åŒ–åŠ›çŸ©å¼ é‡ [num_envs, num_dofs, 1] - å¿…é¡»æ˜¯CPUå¼ é‡ï¼
        all_dof_forces = torch.zeros(self.num_envs, 6, 1, device='cpu')

        # ä¸ºæ¯ä¸ªç¯å¢ƒè®¡ç®—æ§åˆ¶åŠ›çŸ©
        for i in range(self.num_envs):
            if distance_errors[i] > 1e-4:  # åªåœ¨æœ‰æ•ˆæ—¶è®¡ç®—
                joint_control = self._compute_jacobian_control(
                    current_angles[i], current_velocities[i],
                    position_errors[i], actions[i]
                )

                # UR10eå®˜æ–¹åŠ›çŸ©é™åˆ¶ (Nâ‹…m)
                ur10e_torque_limits = [330.0, 330.0, 150.0, 54.0, 54.0, 54.0]  # åŸºäºå®˜æ–¹URDFé…ç½®
                joint_names = ['shoulder_pan', 'shoulder_lift', 'elbow_joint', 'wrist_1', 'wrist_2', 'wrist_3']

                # å°†è®¡ç®—å‡ºçš„åŠ›çŸ©æ”¾å…¥å¼ é‡ï¼ˆå¤„ç†è®¾å¤‡è½¬ç§»ï¼šGPUè®¡ç®— -> CPUå­˜å‚¨ï¼‰
                for j in range(6):  # 6ä¸ªå…³èŠ‚
                    # æå–åŠ›çŸ©å€¼å¹¶ç¡®ä¿å¼ é‡æ ¼å¼
                    if isinstance(joint_control[j], torch.Tensor):
                        force_value = joint_control[j]
                    else:
                        force_value = torch.tensor(float(joint_control[j]), device=self.device)

                    # ä½¿ç”¨UR10eå®˜æ–¹åŠ›çŸ©é™åˆ¶
                    max_torque = ur10e_torque_limits[j]
                    min_torque = -max_torque
                    force_value = torch.clamp(force_value, min_torque, max_torque)

                    # å…³é”®ä¿®å¤ï¼šè½¬ç§»åˆ°CPUæ ‡é‡å€¼ä»¥åŒ¹é…CPUå¼ é‡
                    all_dof_forces[i, j, 0] = force_value.cpu().item()

                # è°ƒè¯•ä¿¡æ¯ï¼ˆä»…ç¬¬ä¸€ä¸ªç¯å¢ƒï¼Œæ¯100æ­¥è¾“å‡ºä¸€æ¬¡ï¼‰
                if i == 0 and hasattr(self, 'debug_step') and self.debug_step % 100 == 0:
                    forces_list = all_dof_forces[i, :, 0].numpy()  # å·²ç»åœ¨CPUä¸Š
                    print(f"   ğŸ”§ åº”ç”¨åŠ›çŸ©: [{forces_list.tolist()}] Nâ‹…m")
                    for j, (name, force, limit) in enumerate(zip(joint_names, forces_list, ur10e_torque_limits)):
                        saturation = abs(force) / limit * 100
                        print(f"      {j+1}. {name:12}: {force:7.2f} Nâ‹…m (é™åˆ¶: Â±{limit:5.1f}, é¥±å’Œåº¦: {saturation:5.1f}%)")

        # ä½¿ç”¨Isaac Gymå®˜æ–¹ç¤ºä¾‹çš„æ­£ç¡®APIï¼šä¸€æ¬¡æ€§è®¾ç½®æ‰€æœ‰ç¯å¢ƒçš„åŠ›çŸ©
        # å‚è€ƒ: gym.set_dof_actuation_force_tensor(sim, gymtorch.unwrap_tensor(u))
        try:
            self.gym.set_dof_actuation_force_tensor(self.sim, gymtorch.unwrap_tensor(all_dof_forces))
            if hasattr(self, 'debug_step') and self.debug_step % 100 == 0:
                print(f"âœ… Isaac GymåŠ›çŸ©è®¾ç½®æˆåŠŸ: å½¢çŠ¶={all_dof_forces.shape}, è®¾å¤‡={all_dof_forces.device}")
        except Exception as e:
            print(f"âŒ Isaac GymåŠ›çŸ©è®¾ç½®å¤±è´¥: {e}")
            print(f"   åŠ›çŸ©å¼ é‡å½¢çŠ¶: {all_dof_forces.shape}")
            print(f"   åŠ›çŸ©å¼ é‡è®¾å¤‡: {all_dof_forces.device}")
            print(f"   åŠ›çŸ©å¼ é‡ç±»å‹: {all_dof_forces.dtype}")
            print(f"   åŠ›çŸ©èŒƒæ•°: {torch.norm(all_dof_forces)}")

    def _compute_jacobian_control(self, current_angles: torch.Tensor,
                                current_velocities: torch.Tensor,
                                position_error: torch.Tensor,
                                action: torch.Tensor) -> torch.Tensor:
        """è®¡ç®—åŸºäºé›…å¯æ¯”çš„æ§åˆ¶"""
        kp_scale, kd_scale, ki_enable = action

        # æ˜ å°„ç¼©æ”¾å› å­
        kp_scale = 0.1 + kp_scale * 2.0  # [0.1, 2.1]
        kd_scale = 0.1 + kd_scale * 2.0  # [0.1, 2.1]
        ki_enable = max(0.0, ki_enable)   # [0.0, 1.0+]

        # ğŸ¯ ä½¿ç”¨å®˜æ–¹UR10e PIDå‚æ•°ï¼ˆæ¥è‡ªisaac_gym_manipulatorå®˜æ–¹é…ç½®ï¼‰
        # å‚è€ƒ: /isaac_gym_manipulator/ros_sources/universal_robot/ur_gazebo/config/ur10e_controllers.yaml
        base_kp = self.config['pid_params']['base_gains']['p']
        base_kd = self.config['pid_params']['base_gains']['d']
        base_ki = self.config['pid_params']['base_gains']['i']

        # RLè°ƒåº¦å‚æ•°ï¼ˆæ¯ä¸ªå…³èŠ‚åˆ†åˆ«è®¡ç®—ï¼‰
        kp = [base_kp[i] * kp_scale for i in range(6)]
        kd = [base_kd[i] * kd_scale for i in range(6)]
        ki = [base_ki[i] * ki_enable for i in range(6)]

        # è®¡ç®—é›…å¯æ¯”çŸ©é˜µï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        jacobian = self._compute_jacobian_batch(current_angles.unsqueeze(0))[0]

        # ğŸ¯ ï¿½ï¿½åŒ–ï¼šæ¯ä¸ªå…³èŠ‚ä½¿ç”¨å„è‡ªçš„kpè¿›è¡Œæ§åˆ¶ï¼ˆå‚è€ƒåŸå§‹MuJoCoå®ç°ï¼‰
        joint_control = torch.zeros(6, device=self.device)

        # å…ˆè½¬æ¢ä»»åŠ¡ç©ºé—´è¯¯å·®åˆ°å…³èŠ‚ç©ºé—´
        joint_position_errors = jacobian.T @ position_error

        # æ¯ä¸ªå…³èŠ‚ä½¿ç”¨å„è‡ªçš„kpã€kdè¿›è¡Œæ§åˆ¶ï¼ˆkiå‚æ•°é¢„ç•™ï¼Œæœªæ¥å¯æ·»åŠ ç§¯åˆ†é¡¹ï¼‰
        for i in range(6):
            # æ¯”ä¾‹ï¿½ï¿½ï¿½ï¼šæ¯ä¸ªå…³èŠ‚ä½¿ç”¨å„è‡ªçš„kp
            p_term = kp[i] * joint_position_errors[i]

            # é˜»å°¼é¡¹ï¼šæ¯ä¸ªå…³èŠ‚ä½¿ç”¨å„è‡ªçš„kd
            d_term = kd[i] * current_velocities[i]

            # ğŸ¯ å®˜æ–¹PIDå‚æ•°å·²é…ç½®ï¼Œç§¯åˆ†é¡¹é¢„ç•™ï¼ˆéœ€è¦è¯¯å·®ç´¯ç§¯çŠ¶æ€ï¼‰
            # i_term = ki[i] * self.integral_errors[i]  # æœªæ¥å¯æ·»åŠ 

            # å…³èŠ‚æ§åˆ¶åŠ›çŸ© = æ¯”ä¾‹é¡¹ - é˜»å°¼é¡¹ (+ ç§¯åˆ†é¡¹)
            joint_control[i] = p_term - d_term

        return joint_control

    def _compute_jacobian_batch(self, joint_angles: torch.Tensor) -> torch.Tensor:
        """æ‰¹é‡è®¡ç®—é›…å¯æ¯”çŸ©é˜µ"""
        # ç¡®ä¿è¾“å…¥å¼ é‡åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        joint_angles = joint_angles.to(self.device)
        batch_size = joint_angles.shape[0]
        jacobian = torch.zeros((batch_size, 3, 6), device=self.device)
        epsilon = 1e-6

        for i in range(batch_size):
            angles_np = joint_angles[i].detach().cpu().numpy()
            jacobian_np = self._compute_jacobian_single(angles_np)
            jacobian[i] = torch.tensor(jacobian_np, device=self.device)

        return jacobian

    def _compute_jacobian_single(self, joint_angles: np.ndarray) -> np.ndarray:
        """è®¡ç®—å•ä¸ªé›…å¯æ¯”çŸ©é˜µ"""
        if self.kinematics is not None:
            current_pos = self.kinematics.get_end_effector_position(joint_angles)
            jacobian = np.zeros((3, 6))

            # æ•°å€¼å¾®åˆ†
            for i in range(6):
                delta_q = np.zeros(6)
                delta_q[i] = 1e-6

                perturbed_pos = self.kinematics.get_end_effector_position(joint_angles + delta_q)
                jacobian[:, i] = (perturbed_pos - current_pos) / 1e-6

            return jacobian
        else:
            # ç®€åŒ–é›…å¯æ¯”çŸ©é˜µè¿‘ä¼¼
            return np.eye(3, 6) * 0.1

    def _compute_rewards_batch(self, actions: torch.Tensor) -> torch.Tensor:
        """
        ğŸ¯ åŸºäºåŸå§‹MuJoCoå®ç°çš„æ‰¹é‡å¥–åŠ±è®¡ç®—ï¼ˆå»é™¤èƒ½è€—å¥–åŠ±ï¼‰

        è®¾è®¡æ€è·¯å‚è€ƒè®ºæ–‡ï¼šr(s_t, a_t) = r_a^t + r_s^t + r_ex^t

        Args:
            actions: PIDè°ƒåº¦åŠ¨ä½œ [num_envs, 3]

        Returns:
            rewards: å¥–åŠ±å€¼ [num_envs]
        """
        # è·å–å½“å‰çŠ¶æ€
        current_angles, current_velocities = self._get_joint_angles_and_velocities()
        current_positions = self._compute_end_effector_positions_batch(current_angles)

        # è®¡ç®—ä½ç½®è¯¯å·®
        position_errors = torch.norm(self.target_positions - current_positions, dim=1)

        # 1. ğŸ¯ ç²¾åº¦å¥–åŠ± r_a^t = -w_a * exp(Ïƒ_a * f_a(Î¸^t))
        # åŸºäºåŸå§‹MuJoCoå®ç°çš„æŒ‡æ•°æƒ©ç½šè®¾è®¡
        f_a_theta = position_errors ** 2  # f_a(Î¸^t) = ||p_d - p||^2

        # ä½¿ç”¨æŒ‡æ•°æƒ©ç½šï¼šè¯¯å·®å°æ—¶æƒ©ç½šæ¸©å’Œï¼Œè¯¯å·®å¤§æ—¶æƒ©ç½šæ€¥å‰§å¢åŠ 
        # ä½¿ç”¨configä¸­çš„sigmaå‚æ•°ï¼Œä¾¿äºè°ƒæ•´æƒ©ç½šçš„é™¡å³­ç¨‹åº¦
        sigma = self.config['reward']['accuracy']['sigma']
        accuracy_reward = -self.config['reward']['accuracy']['weight'] * torch.exp(sigma * f_a_theta)

        # 2. ğŸƒ é€Ÿåº¦å¥–åŠ± r_s^tï¼ˆå¥–åŠ±è¯¯å·®å‡å°‘é€Ÿåº¦ï¼‰
        if self.prev_position_errors is not None:
            error_change = self.prev_position_errors - position_errors
            speed_reward = self.config['reward']['speed']['weight'] * torch.clamp(error_change, min=0.0)
        else:
            speed_reward = torch.zeros_like(position_errors)

        # 3. ğŸ”§ ç¨³å®šæ€§å¥–åŠ±ï¼ˆPIDå‚æ•°å˜åŒ–å¹…åº¦æ§åˆ¶ï¼‰
        stability_reward = -self.config['reward']['stability']['weight'] * (
            torch.abs(actions[:, 0]) + torch.abs(actions[:, 1])  # kp_scale + kd_scale
        )

        # ğŸ“ æ³¨é‡Šæ‰èƒ½è€—å¥–åŠ±ï¼Œä¸“æ³¨äºä½ç½®æ§åˆ¶æ€§èƒ½
        # # 4. èƒ½è€—å¥–åŠ±ï¼ˆå·²ç§»é™¤ï¼‰
        # energy_cost = torch.sum(current_velocities ** 2, dim=1)
        # energy_reward = -self.config['reward']['energy']['weight'] * energy_cost

        # ğŸ æ€»å¥–åŠ±ï¼ˆå»é™¤èƒ½è€—å¥–åŠ±ï¼‰
        total_reward = accuracy_reward + speed_reward + stability_reward

        # ğŸŠ ç¨€ç–æˆåŠŸå¥–åŠ±ï¼ˆåˆ°è¾¾ç›®æ ‡æ—¶çš„é¢å¤–å¥–åŠ±ï¼‰
        success_mask = position_errors < self.config['reward']['accuracy']['threshold']
        total_reward[success_mask] += self.config['reward']['extra']['success_reward']

        # ğŸ’¾ ä¿å­˜è¯¯å·®å†å²ç”¨äºä¸‹æ¬¡è®¡ç®—é€Ÿåº¦å¥–åŠ±
        self.prev_position_errors = position_errors.clone()

        # ğŸ“Š è°ƒè¯•ä¿¡æ¯ï¼ˆæ¯100æ­¥æ‰“å°ä¸€æ¬¡ï¼‰
        if hasattr(self, 'debug_step') and self.debug_step % 100 == 0:
            avg_error = position_errors.mean().item()
            avg_reward = total_reward.mean().item()
            success_rate = success_mask.float().mean().item()
            print(f"ğŸ“ˆ æ­¥éª¤{self.debug_step}: å¹³å‡è¯¯å·®={avg_error:.4f}m, å¹³å‡å¥–åŠ±={avg_reward:.4f}, æˆåŠŸç‡={success_rate:.2%}")

        return total_reward

    def _check_done_batch(self) -> torch.Tensor:
        """æ£€æŸ¥å®Œæˆæ¡ä»¶"""
        # è·å–å½“å‰ä½ç½®
        current_angles, _ = self._get_joint_angles_and_velocities()
        current_positions = self._compute_end_effector_positions_batch(current_angles)

        # è®¡ç®—ä½ç½®è¯¯å·®
        position_errors = torch.norm(self.target_positions - current_positions, dim=1)

        # å®Œæˆæ¡ä»¶ï¼šæˆåŠŸåˆ°è¾¾æˆ–è¶…è¿‡æœ€å¤§æ­¥æ•°
        success_done = position_errors < self.config['reward']['accuracy']['threshold']
        timeout_done = self.episode_steps >= self.max_steps  # ä½¿ç”¨æ¯ä¸ªç¯å¢ƒçš„episodeæ­¥æ•°

        return success_done | timeout_done

    def _get_dof_state_indices(self, env_idx: int):
        """è·å–æŒ‡å®šç¯å¢ƒçš„DOFçŠ¶æ€ç´¢å¼•"""
        # è¿™é‡Œéœ€è¦æ ¹æ®Isaac Gymçš„å…·ä½“å®ç°æ¥è·å–ç´¢å¼•
        # æš‚æ—¶è¿”å›å ä½ç¬¦
        return torch.arange(env_idx * 6, (env_idx + 1) * 6, device=self.device)

    def _get_joint_angles_and_velocities(self) -> tuple:
        """æ­£ç¡®è·å–æ‰€æœ‰ç¯å¢ƒçš„å…³èŠ‚è§’åº¦å’Œé€Ÿåº¦"""
        dof_positions = self.dof_states.view(-1, 2)  # [num_envs * 6, 2]
        current_angles_list = []
        current_velocities_list = []
        for i in range(self.num_envs):
            start_idx = i * 6
            env_angles = dof_positions[start_idx:start_idx+6, 0]  # 6ä¸ªå…³èŠ‚çš„ä½ç½®
            env_vels = dof_positions[start_idx:start_idx+6, 1]   # 6ä¸ªå…³èŠ‚çš„é€Ÿåº¦
            current_angles_list.append(env_angles)
            current_velocities_list.append(env_vels)

        current_angles = torch.stack(current_angles_list)  # [num_envs, 6]
        current_velocities = torch.stack(current_velocities_list)  # [num_envs, 6]

        # ç¡®ä¿å¼ é‡åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        current_angles = current_angles.to(self.device)
        current_velocities = current_velocities.to(self.device)

        return current_angles, current_velocities

    def get_num_envs(self) -> int:
        """è·å–ç¯å¢ƒæ•°é‡"""
        return self.num_envs

    def get_num_actions(self) -> int:
        """è·å–åŠ¨ä½œç»´åº¦"""
        return self.action_dim

    def get_num_obs(self) -> int:
        """è·å–è§‚æµ‹ç»´åº¦"""
        return self.state_dim

    def _draw_target_sphere(self):
        """ç»˜åˆ¶çº¢è‰²ç›®æ ‡çƒä½“ï¼ˆä½¿ç”¨Isaac Gymå®˜æ–¹gymutil APIï¼‰"""
        try:
            # å¯¼å…¥gymutilï¼ˆIsaac Gymå®˜æ–¹è°ƒè¯•ç»˜åˆ¶å·¥å…·ï¼‰
            from isaacgym import gymutil

            # åˆ›å»ºçº¢è‰²çƒä½“å‡ ä½•ä½“ï¼ˆåªåˆ›å»ºä¸€æ¬¡ï¼‰
            if not hasattr(self, '_target_sphere_geom'):
                sphere_rot = gymapi.Quat.from_euler_zyx(0.5 * math.pi, 0, 0)
                sphere_pose = gymapi.Transform(r=sphere_rot)
                # åˆ›å»ºçº¢è‰²çº¿æ¡†çƒä½“ï¼ŒåŠå¾„0.05m
                self._target_sphere_geom = gymutil.WireframeSphereGeometry(0.05, 12, 12, sphere_pose, color=(1, 0, 0))

            # ä¸ºæ¯ä¸ªç¯å¢ƒç»˜åˆ¶ç›®æ ‡ç‚¹
            for i in range(self.num_envs):
                target_pos = self.target_positions[i]

                # åˆ›å»ºç›®æ ‡ç‚¹çš„å˜æ¢ï¼ˆä½ç½®ï¼‰
                sphere_pose = gymapi.Transform()
                sphere_pose.p = gymapi.Vec3(target_pos[0].item(), target_pos[1].item(), target_pos[2].item())
                sphere_pose.r = gymapi.Quat(0, 0, 0, 1)  # æ— æ—‹è½¬

                # ä½¿ç”¨Isaac Gymå®˜æ–¹è°ƒè¯•ç»˜åˆ¶APIç»˜åˆ¶çº¢è‰²çƒä½“
                if hasattr(self, 'viewer') and self.viewer is not None:
                    gymutil.draw_lines(self._target_sphere_geom, self.gym, self.viewer, self.envs[i], sphere_pose)
        except Exception as e:
            # å¦‚æœç»˜åˆ¶å¤±è´¥ï¼Œé™é»˜å¤„ç†ï¼ˆé¿å…ä¸­æ–­è®­ç»ƒï¼‰
            if hasattr(self, 'debug_step') and self.debug_step % 1000 == 0:  # å¶å°”æŠ¥å‘Šé”™è¯¯
                print(f"âš ï¸ ç›®æ ‡ç‚¹ç»˜åˆ¶å¤±è´¥: {e}")
            pass

    def close(self):
        """å…³é—­ç¯å¢ƒ"""
        if hasattr(self, 'viewer') and self.viewer is not None:
            self.gym.destroy_viewer(self.viewer)
        self.gym.destroy_sim(self.sim)