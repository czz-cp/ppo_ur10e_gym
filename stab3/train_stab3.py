#!/usr/bin/env python3

"""
UR10e Stable-Baselines3 PPOè®­ç»ƒè„šæœ¬

åŸºäºstable-baselines3åº“å®ç°çš„UR10eæœºæ¢°è‡‚å¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼Œ
æ›¿ä»£åŸæœ‰çš„è‡ªå®šä¹‰Isaac Gym PPOå®ç°ã€‚

ä¸»è¦ç‰¹æ€§:
- ä½¿ç”¨stable-baselines3çš„PPOå®ç°
- 6Då¢é‡åŠ›çŸ©æ§åˆ¶ (Î”Ï„â‚, Î”Ï„â‚‚, ..., Î”Ï„â‚†)
- Isaac Gymç‰©ç†ä»¿çœŸ
- ä¸åŸå§‹train_isaac_fixed.pyä¿æŒç›¸åŒçš„å‘½ä»¤è¡Œæ¥å£
"""

# IMPORTANT: Isaac Gym must be imported before PyTorch
import os
import sys
import time
import signal
import argparse
import numpy as np
from datetime import datetime
from pathlib import Path

# Isaac Gym imports MUST be before PyTorch
try:
    from isaacgym import gymapi
    from isaacgym import gymtorch
    from isaacgym import gymutil
    from isaacgym.torch_utils import *
    print("âœ… Isaac Gym imported successfully")
except ImportError as e:
    print(f"âŒ Failed to import Isaac Gym: {e}")
    print("Please ensure Isaac Gym is properly installed")
    sys.exit(1)

# Now import PyTorch after Isaac Gym
import torch

# Stable-Baselines3 imports
from stable_baselines3 import PPO
from stable_baselines3.common.env_checker import check_env
from stable_baselines3.common.callbacks import BaseCallback, EvalCallback, CheckpointCallback
from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv
from stable_baselines3.common.monitor import Monitor
from stable_baselines3.common.logger import configure

# Import our utilities after Isaac Gym
from utils_stab3 import (
    load_config_stab3, check_environment, test_basic_isaac_gym,
    test_stable_baselines3_components, get_forced_device,
    setup_training_directories, parse_arguments,
    print_system_info, validate_config, TrainingProgressCallback, exiter
)
from ur10e_env_stab3 import UR10eEnvStab3, make_ur10e_env_stab3

class TrainingMonitorCallback(BaseCallback):
    """è‡ªå®šä¹‰è®­ç»ƒç›‘æ§å›è°ƒ"""

    def __init__(self, eval_freq: int = 10000, save_freq: int = 50000, verbose: int = 1):
        super().__init__(verbose)
        self.eval_freq = eval_freq
        self.save_freq = save_freq
        self.best_mean_reward = -np.inf
        self.start_time = time.time()

    def _on_rollout_start(self) -> None:
        """æ”¶é›†rolloutå‰è°ƒç”¨"""
        pass

    def _on_rollout_end(self) -> None:
        """æ”¶é›†rolloutåè°ƒç”¨"""
        pass

    def _on_step(self) -> bool:
        """æ¯æ­¥åè°ƒç”¨"""
        if self.n_calls % self.eval_freq == 0:
            # è¯„ä¼°å½“å‰ç­–ç•¥
            rewards = []
            distances = []
            successes = 0

            # åˆ›å»ºè¯„ä¼°ç¯å¢ƒ
            eval_env = make_ur10e_env_stab3(
                config_path=self.training_env.envs[0].config_path,
                render=False
            )

            for _ in range(10):  # 10ä¸ªè¯„ä¼°å›åˆ
                obs, _ = eval_env.reset()
                done = False
                episode_reward = 0
                episode_distances = []

                while not done:
                    action, _ = self.model.predict(obs, deterministic=True)
                    obs, reward, terminated, truncated, info = eval_env.step(action)
                    done = terminated or truncated
                    episode_reward += reward
                    episode_distances.append(info.get('distance', 1.0))

                rewards.append(episode_reward)
                distances.append(np.mean(episode_distances))
                if episode_distances[-1] < 0.05:  # æˆåŠŸé˜ˆå€¼
                    successes += 1

            eval_env.close()

            mean_reward = np.mean(rewards)
            mean_distance = np.mean(distances)
            success_rate = successes / 10

            elapsed_time = time.time() - self.start_time

            print(f"\nğŸ“ˆ ç¬¬{self.n_calls}æ­¥è¯„ä¼°:")
            print(f"   ğŸ¯ å¹³å‡å¥–åŠ±: {mean_reward:.4f}")
            print(f"   ğŸ“ å¹³å‡è·ç¦»: {mean_distance:.4f}m")
            print(f"   âœ… æˆåŠŸç‡: {success_rate*100:.1f}%")
            print(f"   â±ï¸ å·²ç”¨æ—¶é—´: {elapsed_time/60:.1f}åˆ†é’Ÿ")

            # è®°å½•åˆ°tensorboard
            self.logger.record('eval/mean_reward', mean_reward)
            self.logger.record('eval/mean_distance', mean_distance)
            self.logger.record('eval/success_rate', success_rate)

        # æ£€æŸ¥ä¼˜é›…é€€å‡º
        if exiter.shutdown:
            print("\nğŸ›‘ æ”¶åˆ°é€€å‡ºä¿¡å·ï¼Œæ­£åœ¨åœæ­¢è®­ç»ƒ...")
            return False

        return True


def make_single_env(config_path: str, device_id: int = 0, render: bool = False):
    """åˆ›å»ºå•ä¸ªç¯å¢ƒçš„å·¥å‚å‡½æ•°"""
    def _init():
        env = make_ur10e_env_stab3(
            config_path=config_path,
            num_envs=1,
            device_id=device_id,
            render=render
        )
        return Monitor(env)
    return _init


def create_vectorized_env(config_path: str, num_envs: int, device_id: int = 0, render: bool = False):
    """åˆ›å»ºå‘é‡åŒ–ç¯å¢ƒ"""
    if num_envs == 1:
        # å•ç¯å¢ƒä½¿ç”¨DummyVecEnv
        env = DummyVecEnv([make_single_env(config_path, device_id, render)])
    else:
        # å¤šç¯å¢ƒä½¿ç”¨SubprocVecEnv
        env = SubprocVecEnv([
            make_single_env(config_path, device_id, render)
            for _ in range(num_envs)
        ])
    return env


def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_arguments()

    print("ğŸš€ UR10e Stable-Baselines3 PPOè®­ç»ƒå¼€å§‹")
    print("=" * 50)
    print(f"é…ç½®æ–‡ä»¶: {args.config}")
    # æå‰è¯»å–configä»¥æ˜¾ç¤ºæ­£ç¡®çš„å‚æ•°ï¼ˆä¸åŸå§‹è„šæœ¬ä¸€è‡´ï¼‰
    try:
        import yaml
        with open(args.config, 'r', encoding='utf-8') as f:
            config_preview = yaml.safe_load(f)
        print(f"å¹¶è¡Œç¯å¢ƒæ•°: {config_preview['env']['num_envs']} (æ¥è‡ªconfig)")
        print(f"GPUè®¾å¤‡: {config_preview['env']['device_id']} (æ¥è‡ªconfig)")
        print(f"è®­ç»ƒå›åˆæ•°: {config_preview.get('train', {}).get('num_episodes', 'N/A')} (æ¥è‡ªconfig)")
    except Exception as e:
        print(f"âš ï¸ è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        print(f"å¹¶è¡Œç¯å¢ƒæ•°: configæ–‡ä»¶è®¾ç½®")
        print(f"GPUè®¾å¤‡: configæ–‡ä»¶è®¾ç½®")
        print(f"è®­ç»ƒå›åˆæ•°: configæ–‡ä»¶è®¾ç½®")
    print(f"ä¿å­˜ç›®å½•: {args.save_dir}")
    print(f"æµ‹è¯•æ¨¡å¼: {'æ˜¯' if args.test else 'å¦'}")
    print("=" * 50)

    # æ‰“å°ç³»ç»Ÿä¿¡æ¯
    print_system_info()

    # åŠ è½½é…ç½®
    print("\nğŸ“‹ åŠ è½½é…ç½®...")
    config = load_config_stab3(args.config)

    # éªŒè¯é…ç½®
    if not validate_config(config):
        print("âŒ é…ç½®éªŒè¯å¤±è´¥")
        sys.exit(1)

    # è¦†ç›–é…ç½®ä¸­çš„å‚æ•°
    if args.render:
        config['visualization']['enable'] = True
    # æ³¨æ„ï¼šargs.timesteps åœ¨åŸå§‹è„šæœ¬ä¸­ä¸å­˜åœ¨ï¼Œä½¿ç”¨é…ç½®ä¸­çš„è®­ç»ƒå‚æ•°

    # ä¿å­˜é…ç½®å‰¯æœ¬
    save_dir = setup_training_directories(args.save_dir)
    config_path = save_dir / "config.yaml"
    import yaml
    with open(config_path, 'w') as f:
        yaml.dump(config, f, default_flow_style=False)
    print(f"ğŸ’¾ é…ç½®å·²ä¿å­˜åˆ°: {config_path}")

    # ç¯å¢ƒæ£€æŸ¥
    print("\nğŸ” ç¯å¢ƒæ£€æŸ¥...")
    if not check_environment():
        print("âŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥")
        sys.exit(1)

    # åŸºæœ¬åŠŸèƒ½æµ‹è¯•
    if not test_basic_isaac_gym():
        print("âŒ Isaac GymåŸºæœ¬åŠŸèƒ½æµ‹è¯•å¤±è´¥")
        sys.exit(1)

    # Stable-Baselines3ç»„ä»¶æµ‹è¯•
    if not test_stable_baselines3_components():
        print("âŒ Stable-Baselines3ç»„ä»¶æµ‹è¯•å¤±è´¥")
        sys.exit(1)

    if args.test:
        print("\nğŸ¯ ä»…æµ‹è¯•æ¨¡å¼ï¼Œå®Œæˆæ‰€æœ‰æµ‹è¯•")
        print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Œç¯å¢ƒå‡†å¤‡å°±ç»ªï¼")
        return True

    # è·å–å¼ºåˆ¶è®¾å¤‡
    device = get_forced_device()

    print(f"\nğŸ¯ å¼€å§‹è®­ç»ƒ...")
    print(f"   è®¾å¤‡: {device}")
    print(f"   ç¯å¢ƒ: {config['env']['num_envs']}xå¹¶è¡Œ")
    print(f"   è®­ç»ƒæ­¥æ•°: {config['ppo']['total_timesteps']}")
    print(f"   ä¿å­˜ç›®å½•: {save_dir}")

    try:
        # åˆ›å»ºç¯å¢ƒ
        print(f"\nğŸ—ï¸ åˆ›å»ºè®­ç»ƒç¯å¢ƒ...")
        num_envs = config.get('env', {}).get('num_envs', 1)
        device_id = config.get('env', {}).get('device_id', 0)

        # åˆ›å»ºå‘é‡åŒ–ç¯å¢ƒ
        train_env = create_vectorized_env(
            config_path=args.config,
            num_envs=num_envs,
            device_id=device_id,
            render=args.render
        )

        print("âœ… ç¯å¢ƒåˆ›å»ºæˆåŠŸ")

        # æ£€æŸ¥ç¯å¢ƒå…¼å®¹æ€§
        print("ğŸ” æ£€æŸ¥ç¯å¢ƒå…¼å®¹æ€§...")
        check_env(train_env.envs[0], warn=True)
        print("âœ… ç¯å¢ƒä¸stable-baselines3å…¼å®¹")

        # è·å–PPOå‚æ•°
        ppo_config = config.get('ppo', {})
        policy_kwargs = ppo_config.get('policy_kwargs', {})

        # åˆ›å»ºPPOæ¨¡å‹
        print(f"\nğŸ¤– åˆ›å»ºPPOæ¨¡å‹...")
        model = PPO(
            policy=ppo_config.get('policy', 'MlpPolicy'),
            env=train_env,
            learning_rate=ppo_config.get('learning_rate', 3e-4),
            n_steps=ppo_config.get('n_steps', 2048),
            batch_size=ppo_config.get('batch_size', 64),
            n_epochs=ppo_config.get('n_epochs', 10),
            gamma=ppo_config.get('gamma', 0.99),
            gae_lambda=ppo_config.get('gae_lambda', 0.95),
            clip_range=ppo_config.get('clip_range', 0.2),
            clip_range_vf=ppo_config.get('clip_range_vf', None),
            normalize_advantage=ppo_config.get('normalize_advantage', True),
            ent_coef=ppo_config.get('ent_coef', 0.01),
            vf_coef=ppo_config.get('vf_coef', 0.5),
            max_grad_norm=ppo_config.get('max_grad_norm', 0.5),
            use_sde=False,  # ä¸ä½¿ç”¨çŠ¶æ€ä¾èµ–æ¢ç´¢
            sde_sample_freq=-1,
            target_kl=ppo_config.get('target_kl', None),
            tensorboard_log=str(save_dir / "logs"),
            policy_kwargs=policy_kwargs,
            verbose=1,
            seed=args.seed,
            device=device
        )

        print("âœ… PPOæ¨¡å‹åˆ›å»ºæˆåŠŸ")

        # æ¢å¤è®­ç»ƒï¼ˆå¦‚æœæŒ‡å®šï¼‰
        if args.resume:
            if os.path.exists(args.resume):
                print(f"ğŸ”„ æ¢å¤è®­ç»ƒ: {args.resume}")
                model = PPO.load(args.resume, env=train_env, device=device)
                print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            else:
                print(f"âš ï¸ æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {args.resume}")
                print("   ä»å¤´å¼€å§‹è®­ç»ƒ")

        # è®¾ç½®å›è°ƒ
        print(f"\nğŸ“Š è®¾ç½®è®­ç»ƒå›è°ƒ...")

        # è¯„ä¼°å›è°ƒ
        eval_env = create_vectorized_env(args.config, 1, device_id, False)
        eval_callback = EvalCallback(
            eval_env,
            best_model_save_path=str(save_dir / "models"),
            log_path=str(save_dir / "evaluations"),
            eval_freq=ppo_config.get('eval_freq', 10000),
            n_eval_episodes=10,  # å›ºå®šä¸º10ï¼Œä¸åŸå§‹è„šæœ¬ä¿æŒä¸€è‡´
            deterministic=True,
            render=False,
            verbose=1
        )

        # æ£€æŸ¥ç‚¹å›è°ƒ
        checkpoint_callback = CheckpointCallback(
            save_freq=ppo_config.get('save_freq', 50000),
            save_path=str(save_dir / "models"),
            name_prefix='ur10e_ppo'
        )

        # è‡ªå®šä¹‰ç›‘æ§å›è°ƒ
        monitor_callback = TrainingMonitorCallback(
            eval_freq=ppo_config.get('eval_freq', 10000),
            save_freq=ppo_config.get('save_freq', 50000),
            verbose=1
        )

        callbacks = [eval_callback, checkpoint_callback, monitor_callback]

        print("âœ… å›è°ƒè®¾ç½®å®Œæˆ")

        # å¼€å§‹è®­ç»ƒ
        print(f"\nğŸ¯ å¼€å§‹PPOè®­ç»ƒ...")
        total_timesteps = ppo_config.get('total_timesteps', 1000000)
        start_time = time.time()

        model.learn(
            total_timesteps=total_timesteps,
            callback=callbacks,
            log_interval=10,
            progress_bar=True
        )

        end_time = time.time()
        training_time = end_time - start_time

        print(f"\nâœ… è®­ç»ƒå®Œæˆï¼")
        print(f"   è®­ç»ƒæ—¶é—´: {training_time/60:.1f}åˆ†é’Ÿ")
        print(f"   è®­ç»ƒæ­¥æ•°: {total_timesteps}")

        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        final_model_path = save_dir / "models" / "ur10e_ppo_final.zip"
        model.save(str(final_model_path))
        print(f"ğŸ’¾ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜: {final_model_path}")

        # å…³é—­ç¯å¢ƒ
        train_env.close()
        eval_env.close()

        return True

    except KeyboardInterrupt:
        print("\nâš ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        return False
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        if args.debug:
            import traceback
            traceback.print_exc()
        return False

    print("\nğŸ‘‹ ç¨‹åºç»“æŸ")


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)